{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNem9EvQSuzS1yRmNJfaWJN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satya-Mohan/Condition-control-statements/blob/main/Untitled18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvKcov5KPBT_",
        "outputId": "8fe99309-4d54-4ed7-f8ba-5f88100d4950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-13 15:30:32--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-04-13 15:30:33--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-04-13 15:30:33--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2023-04-13 15:33:13 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "1SPKCUt0PKkd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Toy training data\n",
        "texts = [\"positive text\", \"negative text\", \"neutral text\", \"positive review\", \"negative review\"]\n",
        "labels = [1, 0, 0, 1, 0]\n",
        "\n",
        "# Text vectorization layer\n",
        "max_tokens = 100 # maximum number of tokens in the vocabulary\n",
        "text_vectorization = layers.TextVectorization(max_tokens=max_tokens)\n",
        "text_vectorization.adapt(texts)"
      ],
      "metadata": {
        "id": "Ap0D4oFiPbcS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parse the unzipped file (a .txt file) to build an index that maps words (as strings) to their vector representation\n",
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "  for line in f:\n",
        "    word, coefs = line.split(maxsplit=1) #it splits the line into two parts, the first part being the word and the second part being the 100-dimensional vector\n",
        "    #print(word, coefs)\n",
        "    coefs = np.fromstring(coefs, \"f\", sep=\" \") #converts the vector from a string to a numpy array of floating-point values\n",
        "    #print(coefs)\n",
        "    #break\n",
        "    embeddings_index[word] = coefs #adds the word and its corresponding vector to the \"embeddings_index\" dictionary\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUI_oRbmPdqS",
        "outputId": "6e71eb08-d06b-4ad5-a364-4330adfe014f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#build an embedding matrix that you can load into an Embedding layer\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary() #Retrieve the vocabulary indexed by our previous TextVectorization layer\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary)))) #Use it to create a mapping from words to their index in the vocabulary\n",
        "\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim)) #Prepare a matrix that we’ll fill with the GloVe vectors.\n",
        " \n",
        "for word, i in word_index.items():\n",
        "  if i < max_tokens:\n",
        "    embedding_vector = embeddings_index.get(word) #Fill entry i in the matrix with the word vector for index i. \n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector #Words not found in the embedding index will be all zeros."
      ],
      "metadata": {
        "id": "JKWu5g9PQqDx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "max_tokens,\n",
        "embedding_dim,\n",
        "embeddings_initializer=keras.initializers.Constant(embedding_matrix), # initializes weights with a constant value - values from embedding_matrix\n",
        "trainable=False,\n",
        ")"
      ],
      "metadata": {
        "id": "yzu2H04oQzwD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.LSTM(32)(embedded)\n",
        "#x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "omyVzIN6RRly"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Iuqdc9ZaRawz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(text_vectorization(texts), np.array(labels), epochs=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXtLZ0oVRjxC",
        "outputId": "e00197af-f6c9-41fe-bf58-6329768ce779"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6827 - accuracy: 0.6000\n",
            "Epoch 2/8\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6515 - accuracy: 0.6000\n",
            "Epoch 3/8\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6290 - accuracy: 0.6000\n",
            "Epoch 4/8\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6088 - accuracy: 0.6000\n",
            "Epoch 5/8\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5892 - accuracy: 0.8000\n",
            "Epoch 6/8\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5693 - accuracy: 0.8000\n",
            "Epoch 7/8\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5490 - accuracy: 0.8000\n",
            "Epoch 8/8\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5279 - accuracy: 0.8000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb40cc894f0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7TpR00_CRnLi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}